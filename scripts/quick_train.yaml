runner: "episode_runner"
mac: "basic_mac"
learner: "q_learner"


t_max: 100               
test_interval: 50          
test_nepisode: 100         
use_replay: true
replay_capacity: 1000
rb_seq_len: 1
rb_batch_episodes: 4
rb_updates_per_step: 3
text_embed_dim: 1024
n_agents: 3
belief_dim: 128
batch_size_run: 1
state_shape: 1024

agent_output_type: "q_values"
action_selector: "multinomial"
obs_last_action: false
obs_agent_id: true
use_causal_mask: false
max_seq_length: 1024
n_actions: 2

# LLM
llm_model_name: "gpt2"
together_api_key: "${TOGETHER_API_KEY}"
coordinator_model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
executor_model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
commitment_embedding_model_name: "BAAI/bge-large-en-v1.5"


env: "huggingface_dataset_env"
env_args:
  hf_dataset_path: "gsm8k"
  hf_dataset_config_name: "main"
  dataset_split: "train"
  max_question_length: 1024
  max_answer_length: 200
  dataset_streaming: false
  use_random_sampling: false      
  random_without_replacement: true
  loop_dataset: true
  use_dataset_episode: false
  max_rounds: 3
  reward:
    initial_weights: [0.4, 0.4, 0.2]


train:
  episodes_per_task: 10
  buffer_size: 8
  batch_size: 4
  update_interval: 5
  optimizer: "adam"
  learning_rate: 0.001
  coordinator_learning_rate: 0.0005
  gamma: 0.99


target_update_tau: 0.005
target_update_interval: 10


lr: 0.0005
belief_net_lr: 0.0005
encoder_lr: 0.0005
mixer_lr: 0.0005
weight_decay: 0.0
episode_length: 3


bne_max_iterations: 3
bne_convergence_threshold: 0.01
stage2_weight: 0.3


arch:
  entity_dim: 128
  attention_heads: 4
  transformer_blocks: 2
  key_dim: 32
  mlp_hidden_size: 128
  feedforward_size: 512
  dropout_rate: 0.1
  layer_norm_epsilon: 0.00001


prompt_attention_heads: 2
commitment_embedding_dim: 1024

# Sampling
sampling:
  temperature_min: 0.1
  temperature_max: 2.0
  p_min: 0.1
  p_max: 0.9

# BNE Configuration
bne:
  enabled: true
  train_refine: true
  max_iterations_train: 2        
  max_iterations_infer: 3        
  refine_at_infer: true          
  convergence_threshold: 0.05    
  early_stop: true


reward:
  max_value: 1.0
  initial_weights: [0.4, 0.4, 0.2]
  eta_alpha: 0.001
  dynamic_alpha_update: true
  r_expected_source: "q_value"
  al_weight: 0.3
  ts_weight: 0.5
  cc_weight: 0.2

# Loss Weights
loss:
  belief_weight: 0.1
  encoder_weight: 0.1
  mixing_weight: 0.1

early_stopping:
  commitment_threshold: 0.05
  loss_threshold: 0.001
  reward_threshold: 0.5
  patience: 3
  min_delta: 0.0
  warmup: 0

system:
  use_cuda: true
  device_num: 0
  seed: 42
  debug: true

logging:
  use_tensorboard: true
  log_interval: 1
  save_model: true
  save_model_interval: 50
  checkpoint_path: "./test_models_small"
  log_path: "./test_logs_small"
  experiment_name: "econ_small_100"

llm:
  together_api_key: "${TOGETHER_API_KEY}"
  coordinator_model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
  executor_model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
  max_tokens: 2048

use_replay: false
